# -*- coding: utf-8 -*-
"""License_Plate_Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fuOpA12YRw9DkgryKgnYO9OEv4MGQlTX
"""

#Import all modules
import torch
import torchvision
from torch.utils.data import DataLoader
from torchvision.models.detection import FasterRCNN
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from torchvision.datasets import CocoDetection
from torchvision.transforms import functional as F
import matplotlib.pyplot as plt
from PIL import Image
import os
from pathlib import Path
from torchvision.models.detection import fasterrcnn_mobilenet_v3_large_fpn

num_classes = 3 # Background + number plate + vehicle                # define no. of classes
BASE_WEIGHTS_PATH = "./weights/"                                     # create empty folder for weights
MODEL_NAME = "FasterRCNN-MobileNet"                                  # model name
num_epochs = 10                                                      # No. of epochs to train model

Path(BASE_WEIGHTS_PATH).mkdir(parents=True, exist_ok=True)                  # path for weights
# Define transformations
class CocoTransform:                                                        # create class for trasfer image into tensor
    def __call__(self, image, target):
        image = F.to_tensor(image)                                           # Convert PIL image to tensor
        return image, target                                                 # return output

# Dataset class
def get_coco_dataset(img_dir, ann_file):                                     # function for load data set and transform
    return CocoDetection(
        root=img_dir,
        annFile=ann_file,
        transforms=CocoTransform()                                           # transform data
    )

# Load datasets
train_dataset = get_coco_dataset(
    img_dir="/content/drive/MyDrive/License_Plate_data/train",                                       # Load Train data
    ann_file="/content/drive/MyDrive/License_Plate_data/train/_annotations.coco.json"                # Load Train annotation json file
)


val_dataset = get_coco_dataset(
    img_dir="/content/drive/MyDrive/License_Plate_data/valid",                                       # Load Valid data
    ann_file="/content/drive/MyDrive/License_Plate_data/valid/_annotations.coco.json"                # Load valid annotation json file
)

# DataLoader
train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))                           # created Train DataLoader
val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))                               # created Valid DataLoader

# Load Faster R-CNN with ResNet-50 backbone
def get_model(num_classes):                                                                                      # create function for models
    # Load pre-trained Faster R-CNN

    if MODEL_NAME == "FasterRCNN-ResNet-FPN":
        model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)                            # Create object of fastRCNN_resnet50_fpn model
    elif MODEL_NAME == "FasterRCNN-MobileNet":
        model = fasterrcnn_mobilenet_v3_large_fpn(pretrained=True)                                                # Create object of fasterrcnn_mobilenet_v3_large_fpn model
    else:
        raise ValueError(f"Unknown model name: {MODEL_NAME}")

    # Get the number of input features for the classifier
    in_features = model.roi_heads.box_predictor.cls_score.in_features

    # Replace the pre-trained head with a new one
    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)
    return model

# Initialize the model
model = get_model(num_classes)

# Move model to GPU if available
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model.to(device)

# Define optimizer and learning rate scheduler
params = [p for p in model.parameters() if p.requires_grad]                                                # set parameters of model
optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)                           # set optimizer for model
lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)                          # create rate scheduler

def train_one_epoch(model, optimizer, data_loader, device, epoch):                                         # create function for train model and accept model,optimizer,data loader,device,epoch
    model.train()
    image_count = 0                                                                                        # set image 0 count
    for images, targets in data_loader:                                                                    # iterate over data loader
        print(f"Epoch No: {epoch} | Image No: {image_count}")                                              # print epoch and image count
        image_count+=1                                                                                     # image count increse by 1
        # Move images to the device
        images = [img.to(device) for img in images]                                                         # move images to device

        # Validate and process targets
        processed_targets = []                                                                              # create empty list for  processed_targets
        valid_images = []                                                                                   # create empty list for valid_images
        for i, target in enumerate(targets):                                                                # iterate over targets
            boxes = []                                                                                      # create empty list for boxes
            labels = []                                                                                     # create empty list for labels
            for obj in target:                                                                              # iterate over target
                # Extract bbox
                bbox = obj["bbox"]  # Format: [x, y, width, height]
                x, y, w, h = bbox

                # Ensure the width and height are positive
                if w > 0 and h > 0:
                    boxes.append([x, y, x + w, y + h])                                                       # Convert to [x_min, y_min, x_max, y_max]
                    labels.append(obj["category_id"])                                                        # Add category_id into labels list

            # Only process if there are valid boxes
            if boxes:
                processed_target = {                                                                          # create dictionary for processed_target
                    "boxes": torch.tensor(boxes, dtype=torch.float32).to(device),
                    "labels": torch.tensor(labels, dtype=torch.int64).to(device),
                }
                processed_targets.append(processed_target)                                                   # added processed_target in processed_target list
                valid_images.append(images[i])                                                               # Add only valid images

        # Skip iteration if no valid targets
        if not processed_targets:
            continue

        # Ensure images and targets are aligned
        images = valid_images

        # Forward pass
        loss_dict = model(images, processed_targets)
        losses = sum(loss for loss in loss_dict.values())

        # Backpropagation
        optimizer.zero_grad()                                                                        # gradient decent optimizer
        losses.backward()                                                                           # backpropagation
        optimizer.step()                                                                            # optimizer step

    print(f"Epoch [{epoch}] Loss: {losses.item():.4f}")                                                # print epoch and loss


print(f"************** TRAINING MODEL_NAME: {MODEL_NAME} **************" )

# Training loop
for epoch in range(num_epochs):                                                                            # iterate over epochs
    print("RUNNING EPOCH => "+str(epoch))                                                                  # print epoch
    train_one_epoch(model, optimizer, train_loader, device, epoch)                                         # call train_one_epoch function
    lr_scheduler.step()                                                                                    # learning rate scheduler step
    # Save the model's state dictionary after every epoch
    model_path = f"{BASE_WEIGHTS_PATH}{MODEL_NAME}_epoch_{epoch + 1}.pth"

    torch.save(model.state_dict(), model_path)                                                            # save model
    print(f"Model saved: {model_path}")                                                                   # print model path with name

COCO_CLASSES = {0: "Background", 1: "License plate", 2: " vehicle"}                      # define coco classes
num_classes = 3                                                                          # no. of classes
MODEL_NAME = "/content/weights/FasterRCNN-MobileNet_epoch_3.pth"                         # load trained model
image_path = "/content/drive/MyDrive/License_Plate_data/th.jpg"                          # new unseen image
threshold = 0.5                                                                          # threshold value

# Load Faster R-CNN with MobileNet backbone
def get_model(num_classes):
    # Load pre-trained Faster R-CNN with monilenet backbone
    model = fasterrcnn_mobilenet_v3_large_fpn(pretrained=True)
    # Get the number of input features for the classifier
    in_features = model.roi_heads.box_predictor.cls_score.in_features
    # Replace the pre-trained head with a new one
    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)
    return model

# Move model to GPU if available
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')

# Load the trained model
model = get_model(num_classes)                                                       # get no. off classes
model.load_state_dict(torch.load(MODEL_NAME))                                         # load trained model
model.to(device)                                                                     # move model to device
model.eval()  # Set the model to evaluation mode

def prepare_image(image_path):
    image = Image.open(image_path).convert("RGB")                                  # Open image
    image_tensor = F.to_tensor(image).unsqueeze(0)                                 # Convert image to tensor and add batch dimension
    return image_tensor.to(device)

# Load the unseen image
image_path = "/content/drive/MyDrive/License_Plate_data/d28d71c2690c16ed_jpg.rf.b7c4b2a5e5870d9fcf8644c109c5457f.jpg"
image_tensor = prepare_image(image_path)                                            # transfer image into tensor

with torch.no_grad():                                                               # Disable gradient computation for inference
    prediction = model(image_tensor)                                                # Perform inference

# `prediction` contains:
# - boxes: predicted bounding boxes
# - labels: predicted class labels
# - scores: predicted scores for each box (confidence level)


def get_class_name(class_id):                                                      # create function for get class name
    return COCO_CLASSES.get(class_id, "Unknown")



def draw_boxes(image, prediction, fig_size=(10, 10)):                              # create function to takes image, prediction,
    boxes = prediction[0]['boxes'].cpu().numpy()                                   # takes value of boxes
    labels = prediction[0]['labels'].cpu().numpy()                                 # takes value of labels
    scores = prediction[0]['scores'].cpu().numpy()                                 # takes value of scores

    plt.figure(figsize=fig_size)                                                   # set size of frame
    plt.imshow(image)                                                              # show image

    for box, label, score in zip(boxes, labels, scores):                           # iterate box, labels, scores
        if score > threshold:                                                      # if score is greater than threshold
            x_min, y_min, x_max, y_max = box                                       # get value of box
            class_name = get_class_name(label)                                     # get class name

            # Set text color based on class
            if class_name == "vehicle":
                text_color = "green"
            elif class_name == "License plate":
                text_color = "blue"
            else:
                text_color = "red"                                                 # fallback/default

            # Draw bounding box (still red)
            plt.gca().add_patch(plt.Rectangle(
                (x_min, y_min),
                x_max - x_min,
                y_max - y_min,
                linewidth=2,                                                       # set width of line
                edgecolor='red',                                                   # set color of line
                facecolor='none'                                                   # set facecolor
            ))

            # Draw text with class-specific color
            plt.text(x_min, y_min - 5, f"{class_name} ({score:.2f})",
                     color=text_color, fontsize=10, weight='bold',
                     bbox=dict(facecolor='white', edgecolor='none', alpha=0.7, pad=1.5))

    plt.axis('off')                                                                # remove axis
    plt.show()                                                                     # show image


# Display the image with bounding boxes and correct labels
draw_boxes(Image.open(image_path), prediction, fig_size=(12, 10))                   # Example of increased size

